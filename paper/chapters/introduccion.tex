\chapter{Introducción}

En el área de la programación concurrente, un programador tiene varias alternativas al momento de implementar una estructura. En principio, uno puede utilizar estructuras como \emph{locks} para controlar que un recurso compartido sea utilizado de una manera correcta que no sea sujeta a problemas tales como las condiciones de carrera.

Sin embargo, este tipo de algoritmos que utilizan locks pueden no ser la mejor opción en varios casos, ya que se puede perder poder de procesamiento cuando hay hilos de ejecución que deben frenar su ejecución para esperar a que un recurso sea liberado a través de su \emph{lock}.

Ante este problema se idearon alternativas en la forma de algoritmos libres de locks. Una alternativa son los algoritmos denominados como optimistas, que no detienen la ejecución de un hilo y utilizan la primitiva de sincronización \emph{compare and set} (CAS) para modificar un recurso compartido, reintentando en el caso de que falle la comparación. Otra alternativa que ha ganado popularidad como práctica para la programación concurrente es el uso de memoria transaccional (STM) donde se permite componer distintas funciones para que luego se realicen de manera atómica y así poder obtener una sincronización correcta de las modificaciones al recurso.
Este método de sincronización permite al programador abstraerse del manejo de \emph{locks} que pueden ser difíciles de mantener y resulta más intuitivo que los algoritmos optimistas para implementar e interpretar.

Dada la variedad de maneras de implementar una misma estructura de datos o interfaz, han surgido varios trabajos que  comparan distintas variantes de implementación para comprender qué manera es preferible dependiendo del contexto de uso. Por ejemplo, en el trabajo de \cite{hash} se implementaron distintas versiones de una tabla hash sobre el lenguaje Haskell para luego realizar experimentos sobre ellas, de una manera similar al trabajo de \cite{linked-list} que tomó una lista enlazada como la estructura de datos a investigar.

En este trabajo se presentan distintas implementaciones para un mismo tipo de datos (pila) concurrente en el lenguaje de programación Haskell. Se presentan tres estructuras de datos distintas para representar la pila concurrente, dos de las cuales utilizan algoritmos optimistas y se encuentran presentadas en \cite{shavit} con implementaciones en código Java, mientras que la restante es una implementación que aprovecha las operaciones de la librería STM de Haskell para facilitar la implementación.
Además, para las estructuras con algoritmos optimistas, también se puede utilizar la librería STM para implementar una versión de CAS sobre STM y que los algoritmos optimistas utilicen variables transaccionales, propias de la librería, similar a como se describe en los trabajos \cite{hash} \cite{linked-list} sobre estructuras de tablas hash y listas enlazadas.
Esto resulta en un total de cinco implementaciones distintas para una pila de datos concurrente.

El objetivo del trabajo es luego realizar comparaciones del desempeño de las distintas estructuras y variantes con una serie de experimentos. Luego, analizar cómo las distintas implementaciones difieren en determinadas situaciones para poder distinguir cuál resulta favorable dependiendo del caso de uso, teniendo en cuenta los aspectos de implementación.

Este trabajo presenta primero los conceptos cruciales para su entendimiento en el capítulo \ref{chap:prelims} como el uso de Haskell como lenguaje imperativo, algoritmos optimistas, y las primitivas de sincronización que fueron utilizadas en la implementación.
Luego se detalla la implementación y el comportamiento de las distintas estructuras de datos para representar una pila concurrente en el capítulo \ref{ch:implementacion}. Finalmente, los detalles de la experimentación realizada y sus resultados se presentan en el capítulo \ref{chap:experiments}.