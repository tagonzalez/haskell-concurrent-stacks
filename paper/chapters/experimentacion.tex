\chapter{Experimentación}\label{chap:experiments}
Los experimentos de este trabajo tienen como objetivo comparar el tiempo de ejecución de los algoritmos en sus distintas variantes de implementación.

Se realizaron varios experimentos preliminares para analizar cómo los parámetros de cada estructura utilizada puede alterar el tiempo de ejecución.
Por ejemplo, se realizó un análisis del rendimiento de un LFS según sus distintos parámetros (tiempos límites mínimos y máximos de backoff) para luego usar la configuración óptima al momento de comparar el rendimiento de la estructura con las demás. Lo mismo ocurrió para la estructura EBS y sus parámetros de capacidad del arreglo y duración del timeout.  Estos experimentos se describen en el apéndice \ref{config-experiments}.

Finalmente, se realizaron tres experimentos comparando las implementaciones, alterando distintas variables como la cantidad de hilos de ejecución, los núcleos de procesamiento, y la proporción de hilos según la operación a realizar (apilar o desapilar).

\section{Detalle de los experimentos}\label{sec:experiment-details}

Para la experimentación se implementó un programa Haskell para ejecutar un escenario en el que varios hilos de ejecución realizan operaciones sobre una pila compartida y se mide el tiempo que transcurre entre el momento de creación de los hilos y el momento en el que todos los hilos terminan de realizar operaciones sobre la pila.

En este programa, cada hilo realizará una cantidad fija de operaciones: los hilos denominados ``lectores'' invocarán llamadas a la función \mintinline{haskell}{pop} mientras que los hilos ``escritores'' apilarán un valor aleatorio a la pila utilizando la función \mintinline{haskell}{push} de la implementación. Una vez que todos los hilos terminan, concluye la ejecución.

Cada programa fue ejecutado un número preciso de veces para luego realizar un promedio y poder obtener una apreciación de la consistencia de los resultados con diagramas \emph{boxplot}.

Los experimentos realizados fueron tres.
Uno estudia cómo varía el tiempo de ejecución respecto de la variación de la proporción de hilos escritores, manteniendo constante la cantidad de hilos totales a lo largo del experimento.
Los otros dos estudian cómo la variación de la cantidad de hilos totales afecta el tiempo de ejecución pero con una distinción, en un experimento la cantidad total de operaciones es distribuída entre los hilos mientras que en el otro se define una cantidad de operaciones que cada hilo debe realizar. Esto implica que en el segundo experimento, cada hilo que se agrega aumenta la cantidad de operaciones totales. En ambos, la proporción de hilos escritores es constante durante todo el experimento.
A continuación se listan los nombres utilizados para identificar a los experimentos:

\begin{itemize}
    \item \mintinline{haskell}{pushPercentages}: proporción de hilos escritores vs. tiempo de ejecución.
    \item \mintinline{haskell}{numberOfThreads}: cantidad de hilos vs. tiempo de ejecución. En este caso la cantidad de operaciones totales aumenta ya que cada hilo debe realizar una cantidad fija de operaciones.
    \item \mintinline{haskell}{numberOfThreadsDist}: mismo análisis que \mintinline{haskell}{numberOfThreads} con la distinción que la cantidad de total de operaciones realizada se mantiene constante para cada cantidad de hilos. Es decir, a medida que aumentan los hilos, cada hilo de ejecución tiene menos operaciones a realizar ya que el total es distruibuido entre más hilos.
\end{itemize}

\subsection{Hipótesis}\label{subsec:hypothesis}
La hipótesis manejada fue que la implementación STM \mintinline{haskell}{StackSTM} mejoraría el tiempo de respuesta a varias, si no todas, las demás implementaciones ya que ha habido mucho trabajo sobre el compilador GHC para poder mejorar la performance de STM.

Esta hipótesis se alinea con resultados similares en \cite{abq}, donde se comparan implementaciones de una cola bloqueante, una utilizando STM y la otra utilizando algoritmos que utilizan locks sobre la estructura de datos.
En \cite{abq}, los resultados muestran que la implementación STM supera a la otra a medida que aumenta la cantidad de núcleos a utilizar por el procesador.

También estuvieron en consideración los resultados de \cite{linked-list} donde se comparan implementaciones similares de una lista simplemente encadenada.
En estos resultados, la implementación sobre STM no obtiene buenos tiempos de ejecución comparada al resto.
Sin embargo, esto se debe a que una lista encadenada se debe recorrer utilizando muchas llamadas a la función \mintinline{haskell}{atomically}.
En el caso de la implementación de \mintinline{haskell}{StackSTM} utilizada en nuestra experimentación, cada operación realiza sólo una llamada a \mintinline{haskell}{atomically}, ya que las operaciones trabajan sólamente con el tope de la pila, y es por eso que es de esperar que los resultados en nuestro caso no se correspondan con los obtenidos en \cite{linked-list}.

\subsection{Instrumentación para realizar los experimentos}\label{subsec:experiment-harness}
Las implementaciones comparadas en los experimentos son \mintinline{haskell}{LockFreeStackIO}, \mintinline{haskell}{LockFreeStackSTM}, \mintinline{haskell}{EliminationBackoffStackIO}, \mintinline{haskell}{EliminationBackoffStackSTM}, y \mintinline{haskell}{StackSTM}. Para cada una de ellas, tendremos un programa Haskell que tomará los siguientes parámetros por línea de comando:

\begin{itemize}
    \item \mintinline{haskell}{min} y \mintinline{haskell}{max}: Los parámetros para la estructura \mintinline{haskell}{LockFreeStack}. Estos consisten de los límites mínimos y máximos de la estructura de backoff que se encuentra detallada en la subsección \ref{sub:backoff}.
    \item \mintinline{haskell}{count} y \mintinline{haskell}{duration}: Los parámetros para la estructura \mintinline{haskell}{EliminationBackoffStack}. Estos son la capacidad del \mintinline{haskell}{EliminationArray} y la duración del timeout a pasar por parámetro en las llamdas a la función \mintinline{haskell}{exchange} de cada \mintinline{haskell}{LockFreeExchanger}.
    \item \mintinline{haskell}{threadCount}: Cantidad de hilos de ejecución que serán creados para operar sobre una pila.
    \item \mintinline{haskell}{distributeOperations}: un valor booleano que determina si el parámetro \mintinline{haskell}{operationCount} se interpreta como la cantidad total de operaciones a ser distribuida entre los hilos o la cantidad que cada hilo debe realizar por separado.
    \item \mintinline{haskell}{operationCount}: Cantidad de operaciones a realizar en el experimento. Estas pueden ser cantidad de operaciones por hilo, o cantidad de operaciones totales que luego serán distribuidas entre la cantidad de hilos según el experimento.
    \item \mintinline{haskell}{pushPercentage}: La proporción de hilos que realizarán operaciones de escritura (\mintinline{haskell}{push}). Se tomará la cantidad de hilos de ejecución y se calculará la cantidad de hilos que realizarán operaciones de escritura sobre la pila según la proporción, el resto realizará operaciones de lectura (\mintinline{haskell}{pop}).
\end{itemize}

El programa se encarga de crear una instancia de pila según la implementación y sus parámetros, luego inserta 100000 elementos para evitar que ocurran excepciones por pila vacía durante la ejecución.
Una vez instanciada la pila, se calcula la cantidad de hilos escritores a crear según la proporción dada por \mintinline{haskell}{pushPercentage} y la cantidad total dada por \mintinline{haskell}{threadCount}. Resta el cálculo de la cantidad de operaciones que debe realizar cada hilo tomando en cuenta los parámetros \mintinline{haskell}{operationCount} y \mintinline{haskell}{distributeOperations}.

Finalmente se inicia un reloj al crear los hilos escritores y lectores para que realicen sus operaciones, y al finalizar todos los hilos, se imprime por pantalla la cantidad de tiempo transcurrido en segundos. Este es el comportamiento de la función \mintinline{haskell}{timeExperiment} que aparece en la penúltima línea de la Fig. \ref{fig:expEBSIO}.

En la Fig. \ref{fig:expEBSIO} se presenta el código Haskell del programa para la implementación \mintinline{haskell}{EliminationBackoffStackIO}.

\begin{figure}[!h]
    \centering
    \begin{minted}[linenos,breaklines,fontsize=\footnotesize]{haskell}
callPushes stack operationCount = do
    if operationCount > 0
        then do
            (randomIO :: IO Int) >>= pushEBSIO stack
            callPushes stack (operationCount - 1)
        else do
            return ()

callPops stack operationCount = do
    if operationCount > 0
        then do
            _ <- catch (popEBSIO stack) (\(e :: EmptyException) -> return 1)
            callPops stack (operationCount - 1)
        else do
            return ()

threadAction isPushThread = if isPushThread then callPushes else callPops

createThreads stack threadCount pushThreadCount operationCount tids = do
    let isPushThread = if pushThreadCount > 0 then True else False
    if threadCount > 0
        then do
            tid <- async (threadAction isPushThread stack operationCount)
            createThreads stack (threadCount - 1) (pushThreadCount - 1) operationCount (tid : tids)
        else
            mapM_ wait tids

parseCommandLineArguments args = do
    -- Get arguments from command line
    capacity <- readIO (args !! 0) :: IO Int
    duration <- readIO (args !! 1) :: IO Integer
    operationCount <- readIO (args !! 2) :: IO Int
    pushPercentage <- readIO (args !! 3) :: IO Float
    threadCount <- readIO (args !! 4) :: IO Int
    distributeOperations <- readIO (args !! 5) :: IO Bool
    -- Distribute operationCount
    operationCount <- return $ if distributeOperations then quot operationCount threadCount else operationCount
    -- Create stack and calculate amount of writer/push threads
    stack <- newEBSIO capacity duration
    let pushThreadCount = floor $ (fromIntegral threadCount :: Float) * pushPercentage
    return (stack, threadCount, operationCount, pushThreadCount)

main = do
    args <- getArgs
    (stack, threadCount, operationCount, pushThreadCount) <- parseCommandLineArguments args
    callPushes stack 1000000
    timeExperiment "" $ createThreads stack threadCount pushThreadCount operationCount []
    \end{minted}
    \caption{Código Haskell para la experimentación sobre la implementación \mintinline{haskell}{EliminationBackoffStackIO}}
    \label{fig:expEBSIO}
\end{figure}

% Fijarse los números de líneas para dejar en claro en qué líneas hay renombre por funciones de otras implementaciónes

Cada uno de los tres experimentos tienen un script bash para ejecutar los programas Haskell variando los parámetros de acorde al experimento, la implementación de pila deseada, y también la cantidad de núcleos del procesador a utilizar.
Una vez determinada la combinación implementación/cantidad de núcleos, se ejecuta el programa Haskell de manera que la variación de parámetros coincida con lo que se quiere observar del experimento.
Es decir, si el experimento en cuestión busca estudiar cómo la proporción de hilos escritores varía el tiempo de ejecución, el script bash se encargará de ejecutar, para cada combinación de implementación-cantidad de núcleos, el programa Haskell de esa implementación variando el valor del parámetro \mintinline{haskell}{pushPercentages} y manteniendo el resto constantes.

Para cada valor que puede tomar la variable \mintinline{haskell}{pushPercentages} en este ejemplo, se realizan varias corridas del mismo programa Haskell y se escribirán los resultados en un archivo CSV para cada combinación implementación-cantidad de núcleos.
Luego los scripts llaman a un programa Python que creará los gráficos utilizando los datos de los archivos CSV.

\subsection{Medición de tiempos}\label{time-measuring}
Para medir el tiempo que toma el programa Haskell en ejecutar todos los hilos de ejecución se utilizó la librería \mintinline{haskell}{clock} \cite{timeMeasuring} de Haskell que provee al programador con distintos tipos de reloj. Se decidió optar por el tipo de reloj \mintinline{haskell}{Monotonic} que no depende del reloj del sistema y por lo tanto no puede ser alterado como el tipo de reloj \mintinline{haskell}{Realtime}.

La función \mintinline{haskell}{timeExperiment} utiliza la función \mintinline{haskell}{getTime} de la librería \mintinline{haskell}{clock} que retorna un valor de tipo \mintinline{haskell}{TimeSpec} el cual luego es convertido a un entero que representa la cantidad de nanosegundos que han transcurrido desde un punto fijo en el pasado como, por ejemplo, el momento de inicio del sistema.
Se realizan dos llamadas a \mintinline{haskell}{getTime}: una antes de la ejecución de la acción a medir e inmediatamente después de su finalización. Finalmente la diferencia es impresa por pantalla en segundos como muestra la Fig. \ref{fig:timeExperiment}.

\begin{figure}[!h]
    \centering
\begin{minted}[linenos,breaklines,fontsize=\footnotesize]{haskell}
timeExperiment action = do
  startTime <- (getTime Monotonic) >>= return.toNanoSecs
  action
  endTime <- (getTime Monotonic) >>= return.toNanoSecs
  let inSecs = (fromIntegral (endTime - startTime)) / (10 ** 9)
  print inSecs
\end{minted}
\caption{Código de la función \mintinline{haskell}{timeExperiment}}
    \label{fig:timeExperiment}
\end{figure}

\subsection{Detalles de compilación}
Se decidió deshabilitar la funcionalidad de \emph{parallel garbage collection} como se menciona en \cite{linked-list}.
Según \cite{linked-list}, el \emph{garbage collector} de GHC presentó dificultades de desempeño cuando se trataba de estructuras que utilizaban el tipo \mintinline{haskell}{TVar}.
Dado que esto se debe a un problema del compilador, y no de la librería STM, se deshabilitó el recolector de basura para no perjudicar los resultados de las implementaciones STM.
Comentarios similares a este se encuentran presentes en \cite{abq}.

Para deshabilitar esta funcionalidad, basta con utilizar la opción \texttt{-I} de GHC que establece cada cuantos segundos debería correr el recolector. Si se le pasa 0 como parámetro a la opción, queda deshabilitada la recollección de basura en tiempo idle \cite{garbagecollection}.

\section{Resultados}\label{sec:results}

% Agregar una referencia a la página de Apple con las especificaciones
Los experimentos fueron realizados utilizando una laptop MacBook Pro del año 2016 con las siguientes especificaciones:

\begin{itemize}
    \item \textbf{Procesador}: 2.0GHz dual-core Intel Core i5, Turbo Boost up to 3.1GHz, with 4MB shared L3 cache
    \item \textbf{Memoria}: 16 GB 1867 MHz LPDDR3
    \item \textbf{Sistema operativo}: macOS Mojave, versión 10.14
\end{itemize}

Dado que el equipo en cuestión tiene un procesador con cuatro núcleos, nuestros experimentos fueron limitados a ser realizados utilizando uno, dos, y cuatro núcleos.

\subsection{Primer experimento: \mintinline{haskell}{pushPercentages}}\label{subsec:pushPercentages}
El experimento \mintinline{haskell}{pushPercentages} consiste en tomar los tiempos de ejecución de cada implementación de pila concurrente, variando la proporción de hilos escritores en cada iteración.
A continuación se listan los parámetros que se mantuvieron constantes durante el experimento.

\begin{itemize}
    \item Cantidad de hilos totales: 20
    \item Cantidad de operaciones realizadas por hilo de ejecución: 10000
    \item Límite mínimo de backoff para las implementaciones de LFS: 100
    \item Límite máximo de backoff para las implementaciones de LFS: 1000
    \item Capacidad del \mintinline{haskell}{EliminationArray} para las implementaciones de EBS: 1
    \item Duración del timeout para las implementaciones de EBS: 100
    \item Cantidad de repeticiones de cada corrida: 10
\end{itemize}

Los resultados, presentados en la Fig. \ref{fig:pushPercentages-all} muestran que las implementaciones de LFS, tanto IO como STM, no parecen variar considerablemente sus tiempos de ejecución según la variación en la proporción de hilos escritores/hilos lectores.
Las pequeñas variaciones que se presentan para estas dos implementaciones pueden ser causa de distintos tiempos de \emph{backoff} determinado de manera aleatoria. Se puede observar este comportamiento en el gráfico de la subfigura \ref{subfig:pushPercentages-lfsio-2} y \ref{subfig:pushPercentages-lfsstm-2}.

\clearpage
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/pushPercentages/plots/1.png}
        \caption{1 núcleo}
        \label{subfig:pushPercentages-1core}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/pushPercentages/plots/2.png}
        \caption{2 núcleos}
        \label{subfig:pushPercentages-2core}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{images/pushPercentages/plots/4.png}
        \caption{4 núcleos}
        \label{subfig:pushPercentages-4core}
    \end{subfigure}
    \caption{Resultados para el experimento \mintinline{haskell}{pushPercentages}}
    \label{fig:pushPercentages-all}
\end{figure}

En cuanto a la implementación de pila sobre STM, \mintinline{haskell}{StackSTM}, vemos que los tiempos de ejecución aumentan a medida que se aumenta la cantidad de hilos escritores.
Una causa posible podría radicar en el hecho que las operaciones de apilar un elemento son más costosas que las de desapilar dado que requieren declarar un nuevo nodo para apilar, lo cual podría resultar en mayores tiempos de ejecución por operación.
La implementación de EBS sobre STM también presenta una tendencia similar, aunque toma tiempos de ejecución mayores a los de \mintinline{haskell}{StackSTM}.

Por otra parte, la implementación de EBS sobre IO tiene resultados menos consistentes que la versión STM.
En las corridas realizadas utilizando 4 núcleos, representados en la Fig. \ref{subfig:pushPercentages-4core}, los tiempos de ejecución son mayores al inicio del experimento, es decir, cuando la proporción de hilos escritores es del 10\%.

Sobre las implementaciones de LFS, los resultados no presentan una tendencia tan marcada como las demás. A medida que la variación en la proporción de hilos escritores varía, los tiempos de ejecución en las implementaciones LFS se mantienen constantes o incrementan levemente como muestran los gráficos de la Fig \ref{fig:pushPercentages-all}. También se puede apreciar que una vez que el programa es ejecutado sobre más de un núcleo del procesador, los resultados para LFS no sufren una variación considerable, mientras que el resto aumenta a medida que aumenta la cantidad de núcleos.

Se presenta un gráfico con los resultados para EBS sobre IO con diagramas \emph{boxplot} para analizar la consistencia de la implementación en la Fig. \ref{fig:pushPercentages-ebsio-4}.
En el gráfico se puede ver que los resultados para una proporción de hilos escritores de 10\% presentan un rango muy amplio y es por eso que se obtiene un valor promedio mayor en esta configuración.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/pushPercentages/plots/expEBSIO-4.png}
    \caption{Resultados de EBS sobre IO, con cuatro núcleos de ejecución}
    \label{fig:pushPercentages-ebsio-4}
\end{figure}

La consistencia de cada implementación para producir los mismos resultados se puede apreciar con los diagramas \emph{boxplot} que se encuentran en la figura \ref{fig:pushPercentages-boxplots}. Estos gráficos muestran los resultados para los experimentos ejecutados utilizando dos núcleos del procesador. Los resultados para uno y cuatro núcleos se encuentran disponibles en la sección \ref{app-pushPercentages} del apéndice \ref{ch:otherResults}.

\clearpage
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/pushPercentages/plots/expEBSIO-2}
        \caption{Resultados para EBS sobre IO}
        \label{subfig:pushPercentages-ebsio-2}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/pushPercentages/plots/expEBSSTM-2}
        \caption{Resultados para EBS sobre STM}
        \label{subfig:pushPercentages-ebsstm-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/pushPercentages/plots/expLFSIO-2}
        \caption{Resultados para LFS sobre IO}
        \label{subfig:pushPercentages-lfsio-2}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/pushPercentages/plots/expLFSSTM-2}
        \caption{Resultados para LFS sobre STM}
        \label{subfig:pushPercentages-lfsstm-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/pushPercentages/plots/expStackSTM-2}
        \caption{Resultados para LFS sobre STM}
        \label{subfig:pushPercentages-stackstm-2}
    \end{subfigure}
    \caption{Comparación de implementaciones IO vs STM del experimento \mintinline{haskell}{pushPercentages}}
    \label{fig:pushPercentages-boxplots}
\end{figure}

\clearpage
\subsection{Segundo experimento: \mintinline{haskell}{numberOfThreads}}\label{subsec:numberOfThreads}
Para este experimento se analizó el comportamiento del tiempo de ejecución a medida que se aumentaron la cantidad de hilos de ejecución y la cantidad de operaciones totales.
Los parámetros tomaron los siguientes valores:

\begin{itemize}
    \item Proporción de hilos escritores: 0.75
    \item Cantidad de operaciones realizadas por hilo de ejecución: 10000
    \item Límite mínimo de backoff para las implementaciones de LFS: 100
    \item Límite máximo de backoff para las implementaciones de LFS: 1000
    \item Capacidad del \mintinline{haskell}{EliminationArray} para las implementaciones de EBS: 1
    \item Duración del timeout para las implementaciones de EBS: 100
    \item Cantidad de repeticiones de cada corrida: 10
\end{itemize}

En este experimento, a medida que incrementa la cantidad de hilos, la cantidad de operaciones totales realizadas sobre la pila incrementa ya que cada hilo nuevo realiza unas 10000 operaciones adicionales sobre la pila.

\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreads/plots/1.png}
        \caption{1 núcleo}
        \label{subfig:numberOfThreads-1core}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreads/plots/2.png}
        \caption{2 núcleos}
        \label{subfig:numberOfThreads-2core}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreads/plots/4.png}
        \caption{4 núcleos}
        \label{subfig:numberOfThreads-4core}
    \end{subfigure}
    \caption{Resultados para el experimento \mintinline{haskell}{numberOfThreads}}
    \label{fig:numberOfThreads-all}
\end{figure}

Se pueden observar resultados similares en los tres gráficos. Una diferencia es que cuando los experimentos son ejecutados utilizando cuatro núcleos del procesador, la implementación \mintinline{haskell}{StackSTM} no resulta ser la óptima y al aumentar la cantidad de hilos de ejecución el tiempo de ejecución es mayor que las implementaciones de LFS como muestra la subfigura \ref{subfig:numberOfThreads-4core}.
En la misma subfigura, vemos que la implementación de EBS sobre IO supera a la implementación sobre STM mientras que en el caso de 1 y 2 núcleos, ambas implementaciones no presentan diferencias considerables en tiempo de ejecución.

Para realizar un análisis más profundo de los experimentos, se analizaron los resultados de las corridas y se generaron gráficos con diagramas \emph{boxplot} para apreciar la consistencia de cada implementación en cuanto a los tiempos de ejecución que logra a través de las corridas repetidas. Estos gráficos se encuentran en la Fig. \ref{fig:numberOfThreads-boxplots}.

En la figura \ref{fig:numberOfThreads-boxplots} se muestran los resultados para cada implementación utilizando dos núcleos del procesador.
En las subfiguras se presentan diagramas \emph{boxplot} que representan el rango de valores que resultaron de correr el programa Haskell en múltiples iteraciones.
La cantidad de veces que la corrida fue repetida está determinada por el parámetro \mintinline{haskell}{iterations}. Observando los gráficos, se puede ver que los resultados para la implementación \mintinline{haskell}{StackSTM} tienen diagramas \emph{boxplot} de menor rango, lo cual implica una mayor consistencia para producir los mismos resultados al repetir el experimento.

Notar que las implementaciones de LFS, tanto IO como STM, presentan los boxplots donde los datos tienen una mayor variación y por lo tanto los tiempos de ejecución son menos consistentes. Sin embargo, se puede observar que a medida que aumentan los núcleos, los tiempos de ejecución de las implementaciones LFS no aumentan considerablemente como las demás implementaciones. Por ejemplo, los tiempos de LFS para dos y cuatro núcleos presentan resultados muy similares, mientras que el resto aumentan sus tiempos de ejecución en el salto de dos a cuatro núcleos.

En el caso de las implementaciones de EBS, observamos también diagramas \emph{boxplot} consistentes, aunque se pueden distinguir anomalías en los resultados, como por ejemplo, en la Subfig. \ref{subfig:numberOfThreads-ebsio-2} dónde se encuentra un resultado por encima de los 8 segundos.

\clearpage
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreads/plots/expEBSIO-2}
        \caption{Resultados para EBS sobre IO}
        \label{subfig:numberOfThreads-ebsio-2}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreads/plots/expEBSSTM-2}
        \caption{Resultados para EBS sobre STM}
        \label{subfig:numberOfThreads-ebsstm-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreads/plots/expLFSIO-2}
        \caption{Resultados para LFS sobre IO}
        \label{subfig:numberOfThreads-lfsio-2}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreads/plots/expLFSSTM-2}
        \caption{Resultados para LFS sobre STM}
        \label{subfig:numberOfThreads-lfsstm-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreads/plots/expStackSTM-2}
        \caption{Resultados para LFS sobre STM}
        \label{subfig:numberOfThreads-stackstm-2}
    \end{subfigure}
    \caption{Comparación de implementaciones IO vs STM del experimento \mintinline{haskell}{numberOfThreads}}
    \label{fig:numberOfThreads-boxplots}
\end{figure}

Los resultados para uno y cuatro núcleos se encuentran disponibles en la sección \ref{ap-numberOfThreads} del apéndice \ref{ch:otherResults}.

\clearpage
\subsection{Tercer experimento: \mintinline{haskell}{numberOfThreadsDist}}
Para este experimento se analizó el comportamiento del tiempo de ejecución a medida que se aumentaron la cantidad de hilos de ejecución mantienendo constante la cantidad total de operaciones realizadas sobre la pila.
Los parámetros tomaron los siguientes valores:

\begin{itemize}
    \item Proporción de hilos escritores: 0.75
    \item Cantidad de operaciones totales: 1000000
    \item Límite mínimo de backoff para las implementaciones de LFS: 100
    \item Límite máximo de backoff para las implementaciones de LFS: 1000
    \item Capacidad del \mintinline{haskell}{EliminationArray} para las implementaciones de EBS: 1
    \item Duración del timeout para las implementaciones de EBS: 100
    \item Cantidad de repeticiones de cada corrida: 10
\end{itemize}

A diferencia del experimento en la subsección \ref{subsec:numberOfThreads}, en este experimento se mantiene constante la cantidad de operaciones totales.
Es decir, a medida que incrementa la cantidad de hilos de ejecución, la cantidad de operaciones se distribuye equitativamente entre los distintos hilos.

Los resultados presentes en la Fig. \ref{fig:numberOfThreadsDist-all} muestran tendencias similares a los experimentos anteriores.
Se mantiene que la implementación con mejores tiempos de ejecución es la de \mintinline{haskell}{StackSTM} para uno y dos núcleos, mientras que en el caso de cuatro núcleos es superada por las implementaciones de LFS.
En este último caso, la diferencia de tiempos entre las implementaciones LFS y la de \mintinline{haskell}{StackSTM} es más notoria que en los experimentos anteriores.

\clearpage
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreadsDist/plots/1.png}
        \caption{1 núcleo}
        \label{subfig:numberOfThreadsDist-1core}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreadsDist/plots/2.png}
        \caption{2 núcleos}
        \label{subfig:numberOfThreadsDist-2core}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreadsDist/plots/4.png}
        \caption{4 núcleos}
        \label{subfig:numberOfThreadsDist-4core}
    \end{subfigure}
    \caption{Resultados para el experimento \mintinline{haskell}{numberOfThreadsDist}}
    \label{fig:numberOfThreadsDist-all}
\end{figure}

Las tendencias parecen indicar que a medida que aumenta la cantidad de hilos el tiempo de ejecución se mantiene dentro de un mismo rango de valores a partir de los 10 hilos de ejecución. Esto se puede ver en las subfiguras de la Fig. \ref{fig:numberOfThreadsDist-all} dónde las líneas no tienen cambios considerables en la tendencia a partir de 10 hilos.
Sin embargo, se observa un comportamiento errático para los tiempos de ejecución de la implementación de EBS sobre IO cuando se corre el programa sobre un núcleo del procesador.
Para observar este caso en más detalle, se presenta la siguiente Fig. \ref{fig:numberOfThreadsDist-EBSIO} donde se muestra los diagramas \emph{boxplot} para los resultados de la implementación de EBS sobre IO con un núcleo del procesador.

\clearpage
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/numberOfThreadsDist/plots/expEBSIO-1.png}
    \caption{Resultados del experimento \mintinline{haskell}{numberOfThreadsDist} para EBS sobre IO}
    \label{fig:numberOfThreadsDist-EBSIO}
\end{figure}

Una vez más, se puede apreciar que la implementación sobre IO de EBS ha presentado irregularidades en sus resultados en la forma de \emph{outliers} o el rango del boxplot en los resultados con 50 hilos de ejecución.
Estas irregularidades son la causa de la tendencia presentada en la subfigura \ref{subfig:numberOfThreadsDist-1core}.
En la Fig. \ref{fig:numberOfThreadsDist-boxplots} se presentan el resto de los gráficos individuales de cada implementación con los diagramas \emph{boxplot} para cada valor.

\clearpage
\begin{figure}[!h]
       \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreadsDist/plots/expEBSIO-2}
        \caption{Resultados para EBS sobre IO}
        \label{subfig:numberOfThreadsDist-ebsio-2}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreadsDist/plots/expEBSSTM-2}
        \caption{Resultados para EBS sobre STM}
        \label{subfig:numberOfThreadsDist-ebsstm-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreadsDist/plots/expLFSIO-2}
        \caption{Resultados para LFS sobre IO}
        \label{subfig:numberOfThreadsDist-lfsio-2}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreadsDist/plots/expLFSSTM-2}
        \caption{Resultados para LFS sobre STM}
        \label{subfig:numberOfThreadsDist-lfsstm-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/numberOfThreadsDist/plots/expStackSTM-2}
        \caption{Resultados para LFS sobre STM}
        \label{subfig:numberOfThreadsDist-stackstm-2}
    \end{subfigure}
    \caption{Comparación de implementaciones IO vs STM del experimento \mintinline{haskell}{numberOfThreadsDist}}
    \label{fig:numberOfThreadsDist-boxplots}
\end{figure}

En la Fig. \ref{fig:numberOfThreadsDist-boxplots} se puede apreciar cómo la implementación de \mintinline{haskell}{StackSTM} sigue siendo la que produce resultados más consistentes a medida que se repiten las corridas.
También se observa nuevamente la presencia de outliers en los resultados para la implementación de EBS sobre IO, como por ejemplo el punto que se puede observar en la subfigura \ref{subfig:numberOfThreadsDist-ebsio-2} dónde una corrida con 60 hilos de ejecución tomó 16 segundos en completarse.
Se pueden observar outliers en otros gráficos como las subfiguras \ref{subfig:numberOfThreadsDist-lfsstm-2} y \ref{subfig:numberOfThreadsDist-ebsstm-2}, pero estos no se encuentran muy alejados del rango de su respectivo \emph{boxplot}.
