\chapter{Introducción}

En el área de la programación concurrente, un programador tiene varias alternativas al momento de implementar una estructura. En principio, uno puede simplemente utilizar estructuras como \emph{locks} para poder controlar que un recurso compartido sea utilizado de una manera correcta que no sea sujeta a problemas tales como las condiciones de carrera.

Sin embargo, este tipo de algoritmos que utilizan locks resultan no ser ideales en varios casos, ya que se puede perder poder de procesamiento cuando hay hilos de ejecución que deben frenar su ejecución para esperar a que un recurso sea liberado a través de su \emph{lock}.

Ante este problema se idearon alternativas en la forma de algoritmos libres de locks. Una alternativa son los algoritmos denominados como optimistas, que no detienen la ejecución de un hilo y utilizan la primitiva de sincronización \emph{compare and set} (CAS) para modificar un recurso compartido, reintentando en el caso de que falle la comparación. Otra alternativa que ha ganado popularidad como práctica para la programación concurrente es el uso de memoria transaccional (STM) dónde se permite componer distintas funciones para que luega sean realizadas de una manera atómica y así poder obtener una sincronización correcta de las modificaciones al recurso.
Este método de sincronización permite al programador abstraerse del manejo de \emph{locks} que pueden ser difíciles de mantener y resulta más intuitivo que los algoritmos optimistas para deducir la correctitud de los algoritmos.

Dada la variedad de maneras de de implementar una misma estructura de datos o interfaz, varios trabajos han surgido que buscaron comparar las distintas variantes de implementación para comprender cual manera es preferible dependiendo de la situación. Por ejemplo, en el trabajo de \cite{hash} se implementaron distintas versiones de una tabla hash sobre el lenguaje Haskell para luego realizar experimentos sobre ellas, de una manera similar al trabajo de \cite{linked-list} que tomó una lista enlazada como la estructura de datos a investigar.

En este trabajo se describen distintas implementaciones para un mismo tipo de datos (pila) concurrente en el lenguaje de programación Haskell. Se presentan tres estructuras de datos distintas para representar la pila concurrente, dos de las cuales utilizan algoritmos optimistas y se encuentran presentadas en \cite{shavit} con implementaciones en código Java, mientras que la restante es una implementación \emph{naive} que aprovecha las operaciones de la librería STM de Haskell para facilitar la implementación.
Además, para las estructuras con algoritmos optimistas, también se puede la librería STM para implementar una versión de CAS sobre STM y que los algoritmos optimistas utilicen variables transaccionales, propias de la librería, similar a como se describe en los trabajos \cite{hash} \cite{linked-list} sobre estructuras de tablas hash y listas enlazadas.
Esto resulta en un total de cinco implementaciones distintas para una pila de datos concurrente.

El objetivo del trabajo es luego realizar comparaciones del desempeño de las distintas estructuras y variantes con una serie de experimentos. Luego, analizar cómo las distintas implementaciones difieren en determinadas situaciones para poder distinguir cual resulta favorable dependiendo del caso de uso, teniendo en cuenta los aspectos de implementación.

A modo de background, este trabajo presenta primero los conceptos cruciales para su entendimiento en el capítulo \ref{chap:prelims} como el uso de Haskell como lenguaje imperativo, algoritmos optimistas, y las primitivas de sincronización que fueron utilizadas en la implementación.
Luego se detalla la implementación y el comportamiento de las distintas estructuras de datos para representar una pila concurrente en el capítulo \ref{ch:implementation}. Finalmente, todo detalle perteneciente a la experimentación realizada y sus resultados se presentan en el capítulo \ref{chap:experiments}.